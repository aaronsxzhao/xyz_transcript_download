# =============================================================================
# LLM API Configuration (for summarization)
# =============================================================================

LLM_API_KEY=your-api-key-here
LLM_BASE_URL=https://api.openai.com/v1
LLM_MODEL=gpt-4o

# =============================================================================
# Whisper Configuration (Speech-to-Text)
# =============================================================================

# Mode: "local" for local model, "api" for OpenAI Whisper API
WHISPER_MODE=local

# Model size: tiny, base, small, medium, large, large-v3, turbo
# Smaller = faster but less accurate, Larger = slower but more accurate
# Recommended: small (good balance), medium (better accuracy)
WHISPER_LOCAL_MODEL=small

# Device: "auto" (auto-detect), "cuda" (NVIDIA GPU), "cpu"
# - auto: Will use CUDA if available, otherwise CPU
# - cuda: Force NVIDIA GPU (requires CUDA drivers)
# - cpu: Force CPU (works everywhere, slower)
WHISPER_DEVICE=auto

# Compute type: "auto", "float16", "int8", "int8_float16", "float32"
# - auto: float16 for GPU, int8 for CPU
# - float16: Fast, requires GPU (recommended for CUDA)
# - int8: Faster, lower memory, works on CPU and GPU
# - int8_float16: INT8 weights with FP16 compute (GPU only)
# - float32: Slowest but most compatible
WHISPER_COMPUTE_TYPE=auto

# Batch size: 0 = auto (16 for GPU, 8 for CPU)
# Higher = faster but uses more memory
# Recommended: 8-16 for GPU, 4-8 for CPU
WHISPER_BATCH_SIZE=0

# =============================================================================
# Whisper API Configuration (only if WHISPER_MODE=api)
# =============================================================================

# API Provider: "groq" (free, very fast) or "openai"
# Groq is recommended - free tier available and 10x faster than real-time
WHISPER_API_PROVIDER=groq

# Groq API Key (recommended - free at https://console.groq.com/keys)
GROQ_API_KEY=your-groq-api-key

# OpenAI API Key (alternative, costs ~$0.006/min)
# OPENAI_API_KEY=your-openai-api-key

# =============================================================================
# Daemon Configuration
# =============================================================================

# Check interval for new episodes (in seconds, default: 1 hour)
XYZ_CHECK_INTERVAL=3600

# Data directory for storing audio, transcripts, and summaries
XYZ_DATA_DIR=./data

# Minimum disk space required (in MB)
MIN_DISK_SPACE_MB=500

# =============================================================================
# Logging
# =============================================================================

# Log level: DEBUG, INFO, WARNING, ERROR, CRITICAL
LOG_LEVEL=INFO

# =============================================================================
# Supabase Configuration (for cloud deployment with user auth)
# =============================================================================

# Get these from your Supabase project settings:
# https://supabase.com/dashboard/project/_/settings/api

# Project URL
# SUPABASE_URL=https://your-project.supabase.co

# Anon/Public key (safe to expose in frontend)
# SUPABASE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# Service Role key (keep secret! only for backend)
# SUPABASE_SERVICE_KEY=eyJhbGciOiJIUzI1NiIsInR5cCI6IkpXVCJ9...

# JWT Secret (optional, for faster token verification)
# SUPABASE_JWT_SECRET=your-jwt-secret
